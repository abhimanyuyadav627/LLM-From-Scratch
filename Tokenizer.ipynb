{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK4cDAXf6fb2P6QObdP2rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhimanyuyadav627/LLM-From-Scratch/blob/main/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "z-6z6f3EA_F5",
        "outputId": "fd73c0c0-c33b-448a-c764-471106debbf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is an Embedding ?**\n",
        "* Embedding - **It is a mapping from discrete objects, such as words , images, or even entire documents, to points in a continous vector space.**\n",
        "* While we can be using pretrained word embeddings but it is a common practice for LLMs to produce their own embeddings that are part of input layer and are updated during training."
      ],
      "metadata": {
        "id": "soubNTKKwoxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREPROCESSING STEPS FOR CREATING EMBEDDINGS\n",
        "\n",
        "##### TOKENIZING TEXT\n",
        "\n",
        "Important Considerations:\n",
        "\n",
        "\n",
        "1. When developing a simple tokenizer,\n",
        " whether we should encode whitespaces as seperate characters or just remove them depends on our application and its requirements. **Removing whitespaces reduces the memory and computing requirements. However, keeping whitespaces can be useful if we train models that are sensitive to the exact structure of the text (for example Python code, which is sensitive to indentation and spacing).**\n",
        "\n",
        "2. Adding special tokens - to deal with unknown words that were not a part of vocabulary(not needed with BPE), to deal with situations where we need a seperator for two unrelated text sources.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4kkz4Tfvy21K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "BNB5BHvzCgFa",
        "outputId": "f5887066-21ec-4df7-853d-1d03977a1d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0,len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i + 1:i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "tr5w9T_z5TSC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CREATING A DATA LOADER"
      ],
      "metadata": {
        "id": "D35q2iWvSEWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(txt,batch_size = 4, max_length = 256, stride = 128, shuffle = True):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset, batch_size = batch_size, shuffle = shuffle\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "ygel0qkdPh-M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YkEkmplKvkfh"
      },
      "outputs": [],
      "source": [
        "max_length = 4\n",
        "# reading raw text from a text file.\n",
        "with open(\"the-verdict.txt\", \"r\") as f:\n",
        "  raw_text = f.read()\n",
        "dataloader = create_data_loader(\n",
        "    raw_text,batch_size = 8, max_length = max_length, stride = 5, shuffle = False\n",
        "    )\n",
        "data_iter = iter(dataloader)\n",
        "inputs,targets = next(data_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CREATING TOKEN EMBEDDINGS"
      ],
      "metadata": {
        "id": "3HBTESOQSwhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 256\n",
        "vocab_size = 50257\n",
        "\n",
        "torch.manual_seed(123)\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "id": "iz02P4VQQsxZ",
        "outputId": "81275fcc-60a6-4042-8461-5eba6836aaf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENCODING WORD POSITIONS\n",
        "\n",
        "While token embeddings provide consistent vector representations for each token, they lack a sense of the token's position in a sequence **(as self attention mechanism is position agnostic)**. To rectify this, two main types of positional embeddings exist: absolute and relative. **OpenAI's GPT models utilize absolute positional embeddings that are added to the token embedding vectors and are optimized during the model training.**\n",
        "  * **Absolute Positional Embeddings** - directly associated with specific positions in a sequence.\n",
        "  * **Relative Positional Embeddings** - the emphasis of relative positional embeddings is on the relative position or distance between tokens. This means the model **learns the relationships in terms of \"how far apart\" rather than \"at which exact position.\"**\n"
      ],
      "metadata": {
        "id": "e2_l08X6S7sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(block_size, output_dim)\n",
        "# the input to the pos_embeddings is usually a placeholder vector torch.arange(block_size), which contains a sequence of numbers 1, 2, ..., up to the maximum input length.\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(block_size))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "id": "88cudU6ORlPh",
        "outputId": "0a307fb1-195d-4c84-dfb1-4f27f47028b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARING FINAL INPUT EMBEDDINGS TO BE FED TO GPT"
      ],
      "metadata": {
        "id": "UBptdzckS_Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "id": "sKmeUBDnRrm7",
        "outputId": "4636bd3a-325c-4e3a-f5a3-19d75653a24a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    }
  ]
}