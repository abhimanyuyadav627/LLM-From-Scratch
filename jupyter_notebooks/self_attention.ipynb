{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CAUSAL SELF-ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "[[[0.43, 0.15, 0.89], # Your\n",
    " [0.55, 0.87, 0.66], # journey\n",
    " [0.57, 0.85, 0.64], # starts\n",
    " [0.22, 0.58, 0.33], # with\n",
    " [0.77, 0.25, 0.10], # one\n",
    " [0.05, 0.80, 0.55]], # step\n",
    " [[0.43, 0.15, 0.89], # Your\n",
    " [0.55, 0.87, 0.66], # journey\n",
    " [0.57, 0.85, 0.64], # starts\n",
    " [0.22, 0.58, 0.33], # with\n",
    " [0.77, 0.25, 0.10], # one\n",
    " [0.05, 0.80, 0.55]]] # step\n",
    ")\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "context_length = inputs.shape[1]\n",
    "d_in = inputs.shape[-1]\n",
    "d_out = 2\n",
    "W_query = nn.Linear(d_in, d_out, bias = False)\n",
    "W_key = nn.Linear(d_in, d_out, bias = False)\n",
    "W_value = nn.Linear(d_in, d_out, bias = False)\n",
    "dropout = nn.Dropout(0.5)\n",
    "mask = torch.triu(torch.ones(context_length,context_length), diagonal = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 2]), torch.Size([2, 6, 2]), torch.Size([2, 6, 2]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = W_key(inputs)\n",
    "keys = W_key(inputs)\n",
    "values = W_value(inputs)\n",
    "queries.shape, keys.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7175,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.8337, 1.0516,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.8237, 1.0358, 1.0204,   -inf,   -inf,   -inf],\n",
       "         [0.4381, 0.5731, 0.5638, 0.3171,   -inf,   -inf],\n",
       "         [0.4121, 0.4597, 0.4549, 0.2368, 0.2412,   -inf],\n",
       "         [0.5663, 0.7649, 0.7516, 0.4284, 0.3005, 0.5847]],\n",
       "\n",
       "        [[0.7175,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.8337, 1.0516,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.8237, 1.0358, 1.0204,   -inf,   -inf,   -inf],\n",
       "         [0.4381, 0.5731, 0.5638, 0.3171,   -inf,   -inf],\n",
       "         [0.4121, 0.4597, 0.4549, 0.2368, 0.2412,   -inf],\n",
       "         [0.5663, 0.7649, 0.7516, 0.4284, 0.3005, 0.5847]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = queries @ keys.transpose(1,2)\n",
    "attn_scores.masked_fill_(mask.bool(),-torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4616, 0.5384, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3020, 0.3509, 0.3471, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2432, 0.2676, 0.2659, 0.2233, 0.0000, 0.0000],\n",
       "         [0.2068, 0.2139, 0.2132, 0.1827, 0.1833, 0.0000],\n",
       "         [0.1656, 0.1905, 0.1888, 0.1502, 0.1372, 0.1677]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4616, 0.5384, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3020, 0.3509, 0.3471, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2432, 0.2676, 0.2659, 0.2233, 0.0000, 0.0000],\n",
       "         [0.2068, 0.2139, 0.2132, 0.1827, 0.1833, 0.0000],\n",
       "         [0.1656, 0.1905, 0.1888, 0.1502, 0.1372, 0.1677]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim = -1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0769, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6040, 0.0000, 0.6942, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4865, 0.0000, 0.5317, 0.4466, 0.0000, 0.0000],\n",
       "         [0.4137, 0.4278, 0.4264, 0.3655, 0.0000, 0.0000],\n",
       "         [0.3311, 0.0000, 0.3775, 0.3004, 0.0000, 0.3355]],\n",
       "\n",
       "        [[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.9231, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6040, 0.7018, 0.6942, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5352, 0.0000, 0.4466, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3666, 0.0000],\n",
       "         [0.3311, 0.3811, 0.3775, 0.0000, 0.0000, 0.3355]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = dropout(torch.softmax(attn_scores/keys.shape[-1]**0.5, dim = -1))\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1178,  0.0542],\n",
       "          [ 0.2136,  0.2514],\n",
       "          [ 0.1003,  0.1752],\n",
       "          [ 0.1386,  0.2044],\n",
       "          [ 0.1957,  0.2655],\n",
       "          [ 0.1548,  0.2119]],\n",
       " \n",
       "         [[-0.1178,  0.0542],\n",
       "          [-0.0544,  0.0250],\n",
       "          [ 0.2395,  0.3390],\n",
       "          [ 0.1694,  0.1945],\n",
       "          [ 0.0340,  0.0293],\n",
       "          [ 0.1879,  0.2541]]], grad_fn=<UnsafeViewBackward0>),\n",
       " torch.Size([2, 6, 2]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = attn_weights @ values\n",
    "context_vec, context_vec.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MULTIHEADED SELF-ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "[[[0.43, 0.15, 0.89], # Your\n",
    " [0.55, 0.87, 0.66], # journey\n",
    " [0.57, 0.85, 0.64], # starts\n",
    " [0.22, 0.58, 0.33], # with\n",
    " [0.77, 0.25, 0.10], # one\n",
    " [0.05, 0.80, 0.55]], # step\n",
    " [[0.43, 0.15, 0.89], # Your\n",
    " [0.55, 0.87, 0.66], # journey\n",
    " [0.57, 0.85, 0.64], # starts\n",
    " [0.22, 0.58, 0.33], # with\n",
    " [0.77, 0.25, 0.10], # one\n",
    " [0.05, 0.80, 0.55]]] # step\n",
    ")\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "context_length = inputs.shape[1]\n",
    "d_in = inputs.shape[-1]\n",
    "num_heads = 2\n",
    "d_out = 2\n",
    "head_dim = d_out // num_heads\n",
    "W_query = nn.Linear(d_in, d_out, bias = False)\n",
    "W_key = nn.Linear(d_in, d_out, bias = False)\n",
    "W_value = nn.Linear(d_in, d_out, bias = False)\n",
    "dropout = nn.Dropout(0.5)\n",
    "out_proj = nn.Linear(d_out, d_out) #Optional\n",
    "mask = torch.triu(torch.ones(context_length,context_length), diagonal = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 2]), torch.Size([2, 6, 2]), torch.Size([2, 6, 2]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, num_tokens, d_in = inputs.shape\n",
    "queries = W_key(inputs)\n",
    "keys = W_key(inputs)\n",
    "values = W_value(inputs)\n",
    "queries.shape, keys.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 2, 1]), torch.Size([2, 6, 2, 1]), torch.Size([2, 6, 2, 1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = keys.view(b, num_tokens, num_heads, head_dim)\n",
    "values = values.view(b, num_tokens, num_heads,head_dim)\n",
    "queries = queries.view(b, num_tokens, num_heads, head_dim)\n",
    "queries.shape, keys.shape, values.shape #batch, num_tokens, num_heads, head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 6, 1]), torch.Size([2, 2, 6, 1]), torch.Size([2, 2, 6, 1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = keys.transpose(1, 2)\n",
    "values = values.transpose(1, 2)\n",
    "queries = queries.transpose(1, 2)\n",
    "queries.shape, keys.shape, values.shape #batch, num_heads, num_tokens, head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.1908, 0.3380, 0.3303, 0.2040, 0.0988, 0.2898],\n",
       "           [0.3380, 0.5989, 0.5853, 0.3614, 0.1752, 0.5135],\n",
       "           [0.3303, 0.5853, 0.5720, 0.3532, 0.1712, 0.5019],\n",
       "           [0.2040, 0.3614, 0.3532, 0.2181, 0.1057, 0.3099],\n",
       "           [0.0988, 0.1752, 0.1712, 0.1057, 0.0512, 0.1502],\n",
       "           [0.2898, 0.5135, 0.5019, 0.3099, 0.1502, 0.4403]],\n",
       " \n",
       "          [[0.4089, 0.6302, 0.6246, 0.3471, 0.3468, 0.4247],\n",
       "           [0.6302, 0.9714, 0.9627, 0.5350, 0.5345, 0.6547],\n",
       "           [0.6246, 0.9627, 0.9540, 0.5302, 0.5297, 0.6488],\n",
       "           [0.3471, 0.5350, 0.5302, 0.2946, 0.2944, 0.3605],\n",
       "           [0.3468, 0.5345, 0.5297, 0.2944, 0.2941, 0.3602],\n",
       "           [0.4247, 0.6547, 0.6488, 0.3605, 0.3602, 0.4412]]],\n",
       " \n",
       " \n",
       "         [[[0.1908, 0.3380, 0.3303, 0.2040, 0.0988, 0.2898],\n",
       "           [0.3380, 0.5989, 0.5853, 0.3614, 0.1752, 0.5135],\n",
       "           [0.3303, 0.5853, 0.5720, 0.3532, 0.1712, 0.5019],\n",
       "           [0.2040, 0.3614, 0.3532, 0.2181, 0.1057, 0.3099],\n",
       "           [0.0988, 0.1752, 0.1712, 0.1057, 0.0512, 0.1502],\n",
       "           [0.2898, 0.5135, 0.5019, 0.3099, 0.1502, 0.4403]],\n",
       " \n",
       "          [[0.4089, 0.6302, 0.6246, 0.3471, 0.3468, 0.4247],\n",
       "           [0.6302, 0.9714, 0.9627, 0.5350, 0.5345, 0.6547],\n",
       "           [0.6246, 0.9627, 0.9540, 0.5302, 0.5297, 0.6488],\n",
       "           [0.3471, 0.5350, 0.5302, 0.2946, 0.2944, 0.3605],\n",
       "           [0.3468, 0.5345, 0.5297, 0.2944, 0.2941, 0.3602],\n",
       "           [0.4247, 0.6547, 0.6488, 0.3605, 0.3602, 0.4412]]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " torch.Size([2, 2, 6, 6]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = queries @ keys.transpose(2,3)\n",
    "attn_scores, attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1908,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.3380, 0.5989,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.3303, 0.5853, 0.5720,   -inf,   -inf,   -inf],\n",
       "          [0.2040, 0.3614, 0.3532, 0.2181,   -inf,   -inf],\n",
       "          [0.0988, 0.1752, 0.1712, 0.1057, 0.0512,   -inf],\n",
       "          [0.2898, 0.5135, 0.5019, 0.3099, 0.1502, 0.4403]],\n",
       "\n",
       "         [[0.4089,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.6302, 0.9714,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.6246, 0.9627, 0.9540,   -inf,   -inf,   -inf],\n",
       "          [0.3471, 0.5350, 0.5302, 0.2946,   -inf,   -inf],\n",
       "          [0.3468, 0.5345, 0.5297, 0.2944, 0.2941,   -inf],\n",
       "          [0.4247, 0.6547, 0.6488, 0.3605, 0.3602, 0.4412]]],\n",
       "\n",
       "\n",
       "        [[[0.1908,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.3380, 0.5989,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.3303, 0.5853, 0.5720,   -inf,   -inf,   -inf],\n",
       "          [0.2040, 0.3614, 0.3532, 0.2181,   -inf,   -inf],\n",
       "          [0.0988, 0.1752, 0.1712, 0.1057, 0.0512,   -inf],\n",
       "          [0.2898, 0.5135, 0.5019, 0.3099, 0.1502, 0.4403]],\n",
       "\n",
       "         [[0.4089,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.6302, 0.9714,   -inf,   -inf,   -inf,   -inf],\n",
       "          [0.6246, 0.9627, 0.9540,   -inf,   -inf,   -inf],\n",
       "          [0.3471, 0.5350, 0.5302, 0.2946,   -inf,   -inf],\n",
       "          [0.3468, 0.5345, 0.5297, 0.2944, 0.2941,   -inf],\n",
       "          [0.4247, 0.6547, 0.6488, 0.3605, 0.3602, 0.4412]]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores.masked_fill_(\n",
    "            mask.bool()[:num_tokens,:num_tokens], -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 1.1297, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.7242, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.4602, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.3910, 0.0000, 0.4204, 0.0000, 0.3728, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.5273, 0.7395, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.5540, 0.5513, 0.0000, 0.0000, 0.0000],\n",
       "           [0.3770, 0.4549, 0.0000, 0.3578, 0.0000, 0.0000],\n",
       "           [0.3124, 0.3932, 0.3909, 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.8703, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.4602, 0.0000, 0.5343, 0.4668, 0.0000, 0.0000],\n",
       "           [0.3910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.3058, 0.3825, 0.0000, 0.0000, 0.2660, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.5273, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.4356, 0.0000, 0.0000],\n",
       "           [0.3770, 0.0000, 0.4527, 0.3578, 0.3577, 0.0000],\n",
       "           [0.3124, 0.3932, 0.0000, 0.0000, 0.0000, 0.3176]]]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " torch.Size([2, 2, 6, 6]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim = -1)\n",
    "attn_weights = dropout(attn_weights)\n",
    "attn_weights, attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 2, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "context_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = context_vec.contiguous().view(b, num_tokens, d_out)\n",
    "context_vec = out_proj(context_vec)\n",
    "context_vec.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c11cbaa05adf0d9699aa6a1bd059a5f32a1af5cf5cd82fabf4bf061a71d12610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
